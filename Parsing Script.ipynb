{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "50409593fc739cdc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Implement a Parser to read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7f2e737ad3fb23ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:38:03.981574100Z",
     "start_time": "2025-09-30T12:38:03.565326200Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "File `'ls'` not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOSError\u001b[39m                                   Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Ani\\IML (Introduction to Machine Learning)\\Classification with Lazy Learning and SVM\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:728\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    727\u001b[39m     fpath = arg_lst[\u001b[32m0\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m728\u001b[39m     filename = \u001b[43mfile_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    729\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Ani\\IML (Introduction to Machine Learning)\\Classification with Lazy Learning and SVM\\venv\\Lib\\site-packages\\IPython\\utils\\path.py:90\u001b[39m, in \u001b[36mget_py_filename\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m     89\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m py_name\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mFile `\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m` not found.\u001b[39m\u001b[33m\"\u001b[39m % name)\n",
      "\u001b[31mOSError\u001b[39m: File `'ls'` not found.",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mException\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrun\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mls\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Ani\\IML (Introduction to Machine Learning)\\Classification with Lazy Learning and SVM\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:2504\u001b[39m, in \u001b[36mInteractiveShell.run_line_magic\u001b[39m\u001b[34m(self, magic_name, line, _stack_depth)\u001b[39m\n\u001b[32m   2502\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mlocal_ns\u001b[39m\u001b[33m'\u001b[39m] = \u001b[38;5;28mself\u001b[39m.get_local_scope(stack_depth)\n\u001b[32m   2503\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m.builtin_trap:\n\u001b[32m-> \u001b[39m\u001b[32m2504\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2506\u001b[39m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[32m   2507\u001b[39m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[32m   2508\u001b[39m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[32m   2509\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic.MAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Ani\\IML (Introduction to Machine Learning)\\Classification with Lazy Learning and SVM\\venv\\Lib\\site-packages\\IPython\\core\\magics\\execution.py:739\u001b[39m, in \u001b[36mExecutionMagics.run\u001b[39m\u001b[34m(self, parameter_s, runner, file_finder)\u001b[39m\n\u001b[32m    737\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m os.name == \u001b[33m'\u001b[39m\u001b[33mnt\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m re.match(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m^\u001b[39m\u001b[33m'\u001b[39m\u001b[33m.*\u001b[39m\u001b[33m'\u001b[39m\u001b[33m$\u001b[39m\u001b[33m\"\u001b[39m,fpath):\n\u001b[32m    738\u001b[39m         warn(\u001b[33m'\u001b[39m\u001b[33mFor Windows, use double quotes to wrap a filename: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33mun \u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmypath\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mmyfile.py\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m739\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    740\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m    741\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m fpath \u001b[38;5;129;01min\u001b[39;00m sys.meta_path:\n",
      "\u001b[31mException\u001b[39m: File `'ls'` not found."
     ]
    }
   ],
   "source": [
    "%run ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7367e8d9da65becf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:38:34.909659700Z",
     "start_time": "2025-09-30T12:38:34.891632700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 21) (activate.bat, line 21)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mFile \u001b[39m\u001b[32m~\\Documents\\Ani\\IML (Introduction to Machine Learning)\\Classification with Lazy Learning and SVM\\venv\\Scripts\\activate.bat:21\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m@REM Don't use () to avoid problems with them in %PATH%\u001b[39m\n            ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 21)\n"
     ]
    }
   ],
   "source": [
    "%run venv/Scripts/activate.bat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "65a80955e1f2d1a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:35:08.938233600Z",
     "start_time": "2025-09-30T12:34:48.899716100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\elias\\documents\\ani\\iml (introduction to machine learning)\\classification with lazy learning and svm\\venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: pandas in c:\\users\\elias\\documents\\ani\\iml (introduction to machine learning)\\classification with lazy learning and svm\\venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\elias\\documents\\ani\\iml (introduction to machine learning)\\classification with lazy learning and svm\\venv\\lib\\site-packages (1.16.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\elias\\documents\\ani\\iml (introduction to machine learning)\\classification with lazy learning and svm\\venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\elias\\documents\\ani\\iml (introduction to machine learning)\\classification with lazy learning and svm\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\elias\\documents\\ani\\iml (introduction to machine learning)\\classification with lazy learning and svm\\venv\\lib\\site-packages (from pandas) (2025.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\elias\\documents\\ani\\iml (introduction to machine learning)\\classification with lazy learning and svm\\venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Using cached scikit_learn-1.7.2-cp312-cp312-win_amd64.whl (8.7 MB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   ------------- -------------------------- 1/3 [joblib]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   -------------------------- ------------- 2/3 [scikit-learn]\n",
      "   ---------------------------------------- 3/3 [scikit-learn]\n",
      "\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy pandas scipy scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:29:22.232334400Z",
     "start_time": "2025-09-30T12:29:19.216322600Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age            workclass    fnlwgt        education  education-num  \\\n",
      "0  66.0  b'Self-emp-not-inc'  174788.0  b'Some-college'           10.0   \n",
      "1  68.0           b'Private'  211162.0       b'HS-grad'            9.0   \n",
      "2  90.0           b'Private'  139660.0  b'Some-college'           10.0   \n",
      "3  52.0           b'Private'  230657.0       b'HS-grad'            9.0   \n",
      "4  25.0           b'Private'   66622.0  b'Some-college'           10.0   \n",
      "\n",
      "          marital-status            occupation      relationship      race  \\\n",
      "0       b'Never-married'              b'Sales'  b'Not-in-family'  b'White'   \n",
      "1  b'Married-civ-spouse'    b'Exec-managerial'        b'Husband'  b'White'   \n",
      "2            b'Divorced'              b'Sales'      b'Unmarried'  b'Black'   \n",
      "3  b'Married-civ-spouse'  b'Machine-op-inspct'        b'Husband'  b'Other'   \n",
      "4       b'Never-married'      b'Other-service'      b'Own-child'  b'White'   \n",
      "\n",
      "         sex  capital-gain  capital-loss  hours-per-week    native-country  \\\n",
      "0  b'Female'           0.0           0.0            20.0  b'United-States'   \n",
      "1    b'Male'           0.0           0.0            40.0  b'United-States'   \n",
      "2  b'Female'           0.0           0.0            37.0  b'United-States'   \n",
      "3    b'Male'        3781.0           0.0            40.0       b'Columbia'   \n",
      "4  b'Female'           0.0           0.0            25.0  b'United-States'   \n",
      "\n",
      "      class  \n",
      "0  b'<=50K'  \n",
      "1  b'<=50K'  \n",
      "2  b'<=50K'  \n",
      "3  b'<=50K'  \n",
      "4  b'<=50K'  \n",
      "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "count  43958.000000  4.395800e+04   43958.000000   43958.00000  43958.000000   \n",
      "mean      38.613813  1.895789e+05      10.071022    1069.54618     88.442809   \n",
      "std       13.679058  1.054813e+05       2.569835    7371.44600    404.924666   \n",
      "min       17.000000  1.228500e+04       1.000000       0.00000      0.000000   \n",
      "25%       28.000000  1.174960e+05       9.000000       0.00000      0.000000   \n",
      "50%       37.000000  1.780740e+05      10.000000       0.00000      0.000000   \n",
      "75%       48.000000  2.374328e+05      12.000000       0.00000      0.000000   \n",
      "max       90.000000  1.490400e+06      16.000000   99999.00000   4356.000000   \n",
      "\n",
      "       hours-per-week  \n",
      "count    43958.000000  \n",
      "mean        40.423882  \n",
      "std         12.368327  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import arff\n",
    "\n",
    "# Function to load ARFF files\n",
    "def load_arff_dataset(base_path, dataset_name, num_splits=10):\n",
    "    \"\"\"\n",
    "    Load a dataset from ARFF files with multiple splits.\n",
    "\n",
    "    Parameters:\n",
    "    - base_path: str, base folder containing datasets\n",
    "    - dataset_name: str, name of the dataset folder (e.g., 'adult')\n",
    "    - num_splits: int, number of folds to load\n",
    "\n",
    "    Returns:\n",
    "    - data_splits: list of tuples, each tuple is (train_df, test_df)\n",
    "    \"\"\"\n",
    "    data_splits = []\n",
    "\n",
    "    dataset_path = os.path.join(base_path, dataset_name)\n",
    "\n",
    "    for i in range(num_splits):\n",
    "        fold_num = f\"{i:06d}\"\n",
    "        train_file = os.path.join(dataset_path, f\"{dataset_name}.fold.{fold_num}.train.arff\")\n",
    "        test_file = os.path.join(dataset_path, f\"{dataset_name}.fold.{fold_num}.test.arff\")\n",
    "\n",
    "        # Load ARFF files\n",
    "        train_data, train_meta = arff.loadarff(train_file)\n",
    "        test_data, test_meta = arff.loadarff(test_file)\n",
    "\n",
    "        # Convert to pandas DataFrame\n",
    "        train_df = pd.DataFrame(train_data)\n",
    "        test_df = pd.DataFrame(test_data)\n",
    "\n",
    "        # Append to list\n",
    "        data_splits.append((train_df, test_df))\n",
    "\n",
    "    return data_splits\n",
    "\n",
    "# Example usage\n",
    "base_path = \"datasetsCBR/datasetsCBR\"\n",
    "dataset_name = \"adult\"\n",
    "num_splits = 5  # Change to the number of splits you want\n",
    "\n",
    "splits = load_arff_dataset(base_path, dataset_name, num_splits)\n",
    "\n",
    "# Access first split\n",
    "train_df, test_df = splits[0]\n",
    "print(train_df.head())\n",
    "print(train_df.describe())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85162baf5d2f3e36",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "###  Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba9f1db61ee7614",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:32:38.626645600Z",
     "start_time": "2025-09-30T12:32:38.611115600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill numeric NaNs with column mean\n",
    "train_df = train_df.fillna(train_df.mean(numeric_only=True))\n",
    "test_df = test_df.fillna(test_df.mean(numeric_only=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e7355646288128",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Normalization / Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "340b8e786527f82",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T12:35:49.026385200Z",
     "start_time": "2025-09-30T12:35:39.140612400Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import (\n",
    "    scale, StandardScaler, MinMaxScaler, Normalizer\n",
    ")\n",
    "numeric_cols = train_df.select_dtypes(include=[\"number\"]).columns\n",
    "\n",
    "# Standardisation (Z-score)\n",
    "train_standardised = scale(train_df[numeric_cols])\n",
    "test_standardised = scale(test_df[numeric_cols])\n",
    "\n",
    "# Mean normalisation (Î¼=0, values ~ -1 to 1)\n",
    "scaler_mean = StandardScaler(with_mean=True, with_std=False)\n",
    "train_mean_norm = scaler_mean.fit_transform(train_df[numeric_cols])\n",
    "test_mean_norm = scaler_mean.transform(test_df[numeric_cols])\n",
    "\n",
    "# Min-Max scaling (0 to 1)\n",
    "scaler_minmax = MinMaxScaler()\n",
    "train_minmax = scaler_minmax.fit_transform(train_df[numeric_cols])\n",
    "test_minmax = scaler_minmax.transform(test_df[numeric_cols])\n",
    "\n",
    "# Unit vector normalization\n",
    "scaler_unit = Normalizer()\n",
    "train_unit = scaler_unit.fit_transform(train_df[numeric_cols])\n",
    "test_unit = scaler_unit.transform(test_df[numeric_cols])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
