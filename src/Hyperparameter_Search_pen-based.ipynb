{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af26e9ad",
   "metadata": {},
   "source": [
    "# Hyperparameter Search Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc304e7",
   "metadata": {},
   "source": [
    "## Set up and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15446a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "from Parser import Parser\n",
    "from IBL import IBL\n",
    "from preprocessing_types import (\n",
    "    NormalizationStrategy, EncodingStrategy,\n",
    "    MissingValuesNumericStrategy, MissingValuesCategoricalStrategy\n",
    ")\n",
    "\n",
    "BASE = \"../datasetsCBR/datasetsCBR\"\n",
    "NUM_SPLITS = 1\n",
    "K_LIST = [3, 5, 7]\n",
    "METRICS = [\"euclidean\", \"cosine\", \"heom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25344622",
   "metadata": {},
   "source": [
    "## Suite Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847d19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(df: pd.DataFrame):\n",
    "    \"\"\"Split last column as y; return X (DF), y (Series), name of target col.\"\"\"\n",
    "    target_col = df.columns[-1]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    return X, y, target_col\n",
    "\n",
    "def cm_to_json(cm: np.ndarray, labels: list | None = None) -> str:\n",
    "    d = {\"labels\": labels if labels is not None else list(range(cm.shape[0])),\n",
    "         \"matrix\": cm.astype(int).tolist()}\n",
    "    return json.dumps(d)\n",
    "\n",
    "def run_suite(\n",
    "    dataset_name: str,\n",
    "    metrics: list[str],\n",
    "    encoding_for_metrics: dict[str, EncodingStrategy | None],\n",
    "    csv_path: str,\n",
    "    run_retentions: list[str],\n",
    "    votes: list[str]\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        enc_strategy = encoding_for_metrics[metric]\n",
    "        # Build a fresh Parser for this metric so preprocessing matches (OHE vs LE)\n",
    "        parser = Parser(\n",
    "            base_path=BASE,\n",
    "            dataset_name=dataset_name,\n",
    "            normalization_strategy=NormalizationStrategy.MEAN_NORMALIZE,   # numeric -> [0,1]\n",
    "            encoding_strategy=enc_strategy,                         # OHE for eucl/cos, LE or None for HEOM\n",
    "            missing_values_numeric_strategy=MissingValuesNumericStrategy.MEDIAN,\n",
    "            missing_values_categorical_strategy=MissingValuesCategoricalStrategy.MODE,\n",
    "            num_splits=NUM_SPLITS,\n",
    "        )\n",
    "\n",
    "        types = parser.get_types()\n",
    "     \n",
    "        for k in K_LIST:\n",
    "            for vote in votes:\n",
    "                for retention in run_retentions:\n",
    "                    for fold in range(NUM_SPLITS):\n",
    "                        train_matrix, test_matrix = parser.get_split(fold)\n",
    "                        X_test, y_test, _ = split_xy(test_matrix)\n",
    "\n",
    "                        ibl = IBL()\n",
    "\n",
    "                        # Time fit + predict\n",
    "                        t0 = time.perf_counter()\n",
    "                        ibl.fit(train_matrix)\n",
    "                        t1 = time.perf_counter()\n",
    "                        preds = ibl.run(test_matrix,  k=k, metric=metric, vote=vote,  retention_policy=retention, types=types)\n",
    "                        \n",
    "                        t2 = time.perf_counter()\n",
    "\n",
    "                        # Metrics\n",
    "                        y_true = np.asarray(y_test)\n",
    "                        y_pred = np.asarray(preds)\n",
    "                        \n",
    "                        acc = accuracy_score(y_true, y_pred)\n",
    "                        prec_macro, rec_macro, f1_macro, _ = precision_recall_fscore_support(\n",
    "                            y_true, y_pred, average=\"macro\", zero_division=0\n",
    "                        )\n",
    "                        # If you want per-class too:\n",
    "                        prec_w, rec_w, f1_w, _ = precision_recall_fscore_support(\n",
    "                            y_true, y_pred, average=\"weighted\", zero_division=0\n",
    "                        )\n",
    "                        labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "                        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "\n",
    "                        rows.append({\n",
    "                            \"dataset\": dataset_name,\n",
    "                            \"fold\": fold,\n",
    "                            \"metric\": metric,\n",
    "                            \"k\": k,\n",
    "                            \"vote\": vote,\n",
    "                            \"retention\": retention,\n",
    "                            \"n_train\": len(train_matrix),\n",
    "                            \"n_test\": len(X_test),\n",
    "                            \"fit_time_s\": t1 - t0,\n",
    "                            \"predict_time_s\": t2 - t1,\n",
    "                            \"total_time_s\": t2 - t0,\n",
    "                            \"accuracy\": acc,\n",
    "                            \"precision_macro\": prec_macro,\n",
    "                            \"recall_macro\": rec_macro,\n",
    "                            \"f1_macro\": f1_macro,\n",
    "                            \"precision_weighted\": prec_w,\n",
    "                            \"recall_weighted\": rec_w,\n",
    "                            \"f1_weighted\": f1_w,\n",
    "                            \"confusion_matrix_json\": cm_to_json(cm, labels=labels.tolist()),\n",
    "                        })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aee2d5",
   "metadata": {},
   "source": [
    "## Main (tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157da00",
   "metadata": {},
   "source": [
    "# refference\n",
    "\n",
    "```\n",
    "VOTES = [\"modified_plurality\", \"borda\"]\n",
    "RETENTIONS = [\"always_retain\", \"never_retain\", \"different_class_retention\", \"DD_retention\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30779333",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m votes = [\u001b[33m\"\u001b[39m\u001b[33mmodified_plurality\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      2\u001b[39m retentions = [\u001b[33m\"\u001b[39m\u001b[33malways_retain\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m df_1 = \u001b[43mrun_suite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madult\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_for_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meuclidean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEncodingStrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mONE_HOT_ENCODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m    \u001b[49m\u001b[43mEncodingStrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mONE_HOT_ENCODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mheom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEncodingStrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLABEL_ENCODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_retentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretentions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvotes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvotes\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mrun_suite\u001b[39m\u001b[34m(dataset_name, metrics, encoding_for_metrics, csv_path, run_retentions, votes)\u001b[39m\n\u001b[32m     49\u001b[39m ibl.fit(train_matrix)\n\u001b[32m     50\u001b[39m t1 = time.perf_counter()\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m preds = \u001b[43mibl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvote\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[43mretention_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretention\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m t2 = time.perf_counter()\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Metrics\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\src\\IBL.py:75\u001b[39m, in \u001b[36mIBL.run\u001b[39m\u001b[34m(self, test_matrix, k, metric, vote, retention_policy, types)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;66;03m# Retention policy\u001b[39;00m\n\u001b[32m     73\u001b[39m retention_start = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[43mretention_polcies\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretention_policy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_nearest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m retention_end = time.time()\n\u001b[32m     79\u001b[39m step_end = time.time()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\src\\retention_policies.py:8\u001b[39m, in \u001b[36mretention_polcies\u001b[39m\u001b[34m(retention_policy, train_matrix, instance, k_nearest, pred, y)\u001b[39m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m retention_policy == \u001b[33m\"\u001b[39m\u001b[33malways_retain\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     train_matrix = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minstance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m retention_policy == \u001b[33m\"\u001b[39m\u001b[33mdifferent_class_retention\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     10\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m instance.iloc[-\u001b[32m1\u001b[39m] != pred:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:395\u001b[39m, in \u001b[36mconcat\u001b[39m\u001b[34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[39m\n\u001b[32m    380\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    382\u001b[39m op = _Concatenator(\n\u001b[32m    383\u001b[39m     objs,\n\u001b[32m    384\u001b[39m     axis=axis,\n\u001b[32m   (...)\u001b[39m\u001b[32m    392\u001b[39m     sort=sort,\n\u001b[32m    393\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\.venv\\Lib\\site-packages\\pandas\\core\\reshape\\concat.py:684\u001b[39m, in \u001b[36m_Concatenator.get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    680\u001b[39m             indexers[ax] = obj_labels.get_indexer(new_labels)\n\u001b[32m    682\u001b[39m     mgrs_indexers.append((obj._mgr, indexers))\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m new_data = \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[32m    688\u001b[39m     new_data._consolidate_inplace()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:189\u001b[39m, in \u001b[36mconcatenate_managers\u001b[39m\u001b[34m(mgrs_indexers, axes, concat_axis, copy)\u001b[39m\n\u001b[32m    187\u001b[39m     fastpath = blk.values.dtype == values.dtype\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     values = \u001b[43m_concatenate_join_units\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjoin_units\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    190\u001b[39m     fastpath = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    192\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\concat.py:486\u001b[39m, in \u001b[36m_concatenate_join_units\u001b[39m\u001b[34m(join_units, copy)\u001b[39m\n\u001b[32m    483\u001b[39m     concat_values = ensure_block_shape(concat_values, \u001b[32m2\u001b[39m)\n\u001b[32m    485\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m486\u001b[39m     concat_values = \u001b[43mconcat_compat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m empty_dtype != empty_dtype_future:\n\u001b[32m    489\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m empty_dtype == concat_values.dtype:\n\u001b[32m    490\u001b[39m         \u001b[38;5;66;03m# GH#39122, GH#40893\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\concat.py:126\u001b[39m, in \u001b[36mconcat_compat\u001b[39m\u001b[34m(to_concat, axis, ea_compat_axis)\u001b[39m\n\u001b[32m    115\u001b[39m         warnings.warn(\n\u001b[32m    116\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe behavior of array concatenation with empty entries is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    117\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdeprecated. In a future version, this will no longer exclude \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m             stacklevel=find_stack_level(),\n\u001b[32m    123\u001b[39m         )\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     to_concat = \u001b[43m[\u001b[49m\u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mto_concat\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_concat[\u001b[32m0\u001b[39m], np.ndarray):\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# i.e. isinstance(to_concat[0], ExtensionArray)\u001b[39;00m\n\u001b[32m    130\u001b[39m     to_concat_eas = cast(\u001b[33m\"\u001b[39m\u001b[33mSequence[ExtensionArray]\u001b[39m\u001b[33m\"\u001b[39m, to_concat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\concat.py:126\u001b[39m, in \u001b[36m<listcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    115\u001b[39m         warnings.warn(\n\u001b[32m    116\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe behavior of array concatenation with empty entries is \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    117\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mdeprecated. In a future version, this will no longer exclude \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    122\u001b[39m             stacklevel=find_stack_level(),\n\u001b[32m    123\u001b[39m         )\n\u001b[32m    125\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m target_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m     to_concat = [\u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_dtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m arr \u001b[38;5;129;01min\u001b[39;00m to_concat]\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(to_concat[\u001b[32m0\u001b[39m], np.ndarray):\n\u001b[32m    129\u001b[39m     \u001b[38;5;66;03m# i.e. isinstance(to_concat[0], ExtensionArray)\u001b[39;00m\n\u001b[32m    130\u001b[39m     to_concat_eas = cast(\u001b[33m\"\u001b[39m\u001b[33mSequence[ExtensionArray]\u001b[39m\u001b[33m\"\u001b[39m, to_concat)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:185\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    182\u001b[39m     values = _astype_nansafe(values, dtype, copy=copy)\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    186\u001b[39m     values = np.array(values, dtype=\u001b[38;5;28mobject\u001b[39m)\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m values\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "votes = [\"modified_plurality\"]\n",
    "retentions = [\"always_retain\"]\n",
    "\n",
    "df_1 = run_suite(\n",
    "    dataset_name=\"adult\",\n",
    "    metrics=METRICS,\n",
    "    encoding_for_metrics={\n",
    "        \"euclidean\": EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"cosine\":    EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"heom\": EncodingStrategy.LABEL_ENCODE, \n",
    "    },\n",
    "    csv_path=\"test.csv\",\n",
    "    run_retentions=retentions, \n",
    "    votes=votes\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
