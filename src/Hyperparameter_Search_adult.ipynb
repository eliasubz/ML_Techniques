{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af26e9ad",
   "metadata": {},
   "source": [
    "# Hyperparameter Search Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc304e7",
   "metadata": {},
   "source": [
    "## Set up and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15446a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "from Parser import Parser\n",
    "from IBL import IBL\n",
    "from preprocessing_types import (\n",
    "    NormalizationStrategy, EncodingStrategy,\n",
    "    MissingValuesNumericStrategy, MissingValuesCategoricalStrategy\n",
    ")\n",
    "\n",
    "BASE = \"../datasetsCBR/datasetsCBR\"\n",
    "NUM_SPLITS = 1\n",
    "K_LIST = [3, 5, 7]\n",
    "METRICS = [\"euclidean\", \"cosine\", \"heom\"] \n",
    "votes = [\"modified_plurality\", \"borda\"]\n",
    "retentions = [\"always_retain\", \"never_retain\", \"different_class_retention\", \"DD_retention\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25344622",
   "metadata": {},
   "source": [
    "## Suite Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "847d19bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_xy(df: pd.DataFrame):\n",
    "    \"\"\"Split last column as y; return X (DF), y (Series), name of target col.\"\"\"\n",
    "    target_col = df.columns[-1]\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    return X, y, target_col\n",
    "\n",
    "def cm_to_json(cm: np.ndarray, labels: list | None = None) -> str:\n",
    "    d = {\"labels\": labels if labels is not None else list(range(cm.shape[0])),\n",
    "         \"matrix\": cm.astype(int).tolist()}\n",
    "    return json.dumps(d)\n",
    "\n",
    "def run_suite(\n",
    "    dataset_name: str,\n",
    "    metrics: list[str],\n",
    "    encoding_for_metrics: dict[str, EncodingStrategy | None],\n",
    "    csv_path: str,\n",
    "    run_retentions: list[str],\n",
    "    votes: list[str]\n",
    "):\n",
    "    rows = []\n",
    "\n",
    "    for metric in metrics:\n",
    "        enc_strategy = encoding_for_metrics[metric]\n",
    "        # Fresh Parser per metric so preprocessing matches (OHE vs LE)\n",
    "        parser = Parser(\n",
    "            base_path=BASE,\n",
    "            dataset_name=dataset_name,\n",
    "            normalization_strategy=NormalizationStrategy.MEAN_NORMALIZE,\n",
    "            encoding_strategy=enc_strategy,  # OHE for eucl/cos; LE (or None) for HEOM\n",
    "            missing_values_numeric_strategy=MissingValuesNumericStrategy.MEDIAN,\n",
    "            missing_values_categorical_strategy=MissingValuesCategoricalStrategy.MODE,\n",
    "            num_splits=NUM_SPLITS,\n",
    "        )\n",
    "        types = parser.get_types()\n",
    "\n",
    "        for k in K_LIST:\n",
    "            for vote in votes:\n",
    "                for retention in run_retentions:\n",
    "                    # ---------------------------\n",
    "                    # ACCUMULATORS FOR THIS BRANCH\n",
    "                    # ---------------------------\n",
    "                    fit_times = []\n",
    "                    pred_times = []\n",
    "                    total_times = []\n",
    "\n",
    "                    accs = []\n",
    "                    prec_macros = []\n",
    "                    rec_macros = []\n",
    "                    f1_macros = []\n",
    "                    prec_weighteds = []\n",
    "                    rec_weighteds = []\n",
    "                    f1_weighteds = []\n",
    "\n",
    "                    # We’ll build a consistent label set across folds for CM aggregation\n",
    "                    labels_union = None\n",
    "                    cm_aggregate = None\n",
    "\n",
    "                    for fold in range(NUM_SPLITS):\n",
    "                        train_matrix, test_matrix = parser.get_split(fold)\n",
    "                        X_test, y_test, _ = split_xy(test_matrix)\n",
    "\n",
    "                        print(f\"metric={metric} | k={k} | vote={vote} | retention={retention} | fold={fold}\")\n",
    "\n",
    "                        ibl = IBL()\n",
    "\n",
    "                        # Fit + predict\n",
    "                        t0 = time.perf_counter()\n",
    "                        ibl.fit(train_matrix)\n",
    "                        t1 = time.perf_counter()\n",
    "                        preds = ibl.run(\n",
    "                            test_matrix,\n",
    "                            k=k,\n",
    "                            metric=metric,\n",
    "                            vote=vote,\n",
    "                            retention_policy=retention,\n",
    "                            types=types\n",
    "                        )\n",
    "                        t2 = time.perf_counter()\n",
    "\n",
    "                        # Times\n",
    "                        fit_times.append(t1 - t0)\n",
    "                        pred_times.append(t2 - t1)\n",
    "                        total_times.append(t2 - t0)\n",
    "\n",
    "                        # Metrics\n",
    "                        y_true = np.asarray(y_test)\n",
    "                        y_pred = np.asarray(preds)\n",
    "\n",
    "                        accs.append(accuracy_score(y_true, y_pred))\n",
    "\n",
    "                        pm, rm, fm, _ = precision_recall_fscore_support(\n",
    "                            y_true, y_pred, average=\"macro\", zero_division=0\n",
    "                        )\n",
    "                        prec_macros.append(pm)\n",
    "                        rec_macros.append(rm)\n",
    "                        f1_macros.append(fm)\n",
    "\n",
    "                        pw, rw, fw, _ = precision_recall_fscore_support(\n",
    "                            y_true, y_pred, average=\"weighted\", zero_division=0\n",
    "                        )\n",
    "                        prec_weighteds.append(pw)\n",
    "                        rec_weighteds.append(rw)\n",
    "                        f1_weighteds.append(fw)\n",
    "\n",
    "                        # Confusion matrix aggregation with a consistent label order\n",
    "                        fold_labels = np.unique(np.concatenate([y_true, y_pred]))\n",
    "                        if labels_union is None:\n",
    "                            labels_union = fold_labels\n",
    "                        else:\n",
    "                            labels_union = np.unique(np.concatenate([labels_union, fold_labels]))\n",
    "\n",
    "                    # After we know labels_union, recompute & sum CMs across folds in that order\n",
    "                    # (We need a second pass or we can store y_true/y_pred per fold; here we do a second pass quickly)\n",
    "                    # To avoid re-running the model, we’ll store predictions in a quick pass above if desired.\n",
    "                    # Simpler: re-loop folds once more to aggregate CM (cheap vs training).\n",
    "                    cm_aggregate = np.zeros((labels_union.size, labels_union.size), dtype=int)\n",
    "                    for fold in range(NUM_SPLITS):\n",
    "                        train_matrix, test_matrix = parser.get_split(fold)\n",
    "                        X_test, y_test, _ = split_xy(test_matrix)\n",
    "\n",
    "                        ibl = IBL()\n",
    "                        ibl.fit(train_matrix)\n",
    "                        preds = ibl.run(\n",
    "                            test_matrix,\n",
    "                            k=k,\n",
    "                            metric=metric,\n",
    "                            vote=vote,\n",
    "                            retention_policy=retention,\n",
    "                            types=types\n",
    "                        )\n",
    "\n",
    "                        y_true = np.asarray(y_test)\n",
    "                        y_pred = np.asarray(preds)\n",
    "                        cm = confusion_matrix(y_true, y_pred, labels=labels_union)\n",
    "                        cm_aggregate += cm.astype(int)\n",
    "\n",
    "                    # Compute means (and stds) across folds\n",
    "                    def mean_std(a):\n",
    "                        a = np.asarray(a, dtype=float)\n",
    "                        return float(np.mean(a)), float(np.std(a, ddof=0))\n",
    "\n",
    "                    fit_mean, fit_std = mean_std(fit_times)\n",
    "                    pred_mean, pred_std = mean_std(pred_times)\n",
    "                    total_mean, total_std = mean_std(total_times)\n",
    "\n",
    "                    acc_mean, acc_std = mean_std(accs)\n",
    "                    pM_mean, pM_std = mean_std(prec_macros)\n",
    "                    rM_mean, rM_std = mean_std(rec_macros)\n",
    "                    fM_mean, fM_std = mean_std(f1_macros)\n",
    "\n",
    "                    pW_mean, pW_std = mean_std(prec_weighteds)\n",
    "                    rW_mean, rW_std = mean_std(rec_weighteds)\n",
    "                    fW_mean, fW_std = mean_std(f1_weighteds)\n",
    "\n",
    "                    # Row for this (dataset, metric, k, vote, retention)\n",
    "                    rows.append({\n",
    "                        \"dataset\": dataset_name,\n",
    "                        \"metric\": metric,\n",
    "                        \"k\": k,\n",
    "                        \"vote\": vote,\n",
    "                        \"retention\": retention,\n",
    "                        \"num_folds\": NUM_SPLITS,\n",
    "\n",
    "                        # Train/test sizes vary per fold; reporting averages is reasonable\n",
    "                        \"n_train_mean\": float(np.mean([len(parser.get_split(f)[0]) for f in range(NUM_SPLITS)])),\n",
    "                        \"n_test_mean\":  float(np.mean([len(parser.get_split(f)[1]) for f in range(NUM_SPLITS)])),\n",
    "\n",
    "                        # Times\n",
    "                        \"fit_time_s_mean\": fit_mean,\n",
    "                        \"fit_time_s_std\":  fit_std,\n",
    "                        \"predict_time_s_mean\": pred_mean,\n",
    "                        \"predict_time_s_std\":  pred_std,\n",
    "                        \"total_time_s_mean\": total_mean,\n",
    "                        \"total_time_s_std\":  total_std,\n",
    "\n",
    "                        # Metrics (mean ± std over folds)\n",
    "                        \"accuracy_mean\": acc_mean,\n",
    "                        \"accuracy_std\":  acc_std,\n",
    "\n",
    "                        \"precision_macro_mean\": pM_mean,\n",
    "                        \"precision_macro_std\":  pM_std,\n",
    "                        \"recall_macro_mean\":    rM_mean,\n",
    "                        \"recall_macro_std\":     rM_std,\n",
    "                        \"f1_macro_mean\":        fM_mean,\n",
    "                        \"f1_macro_std\":         fM_std,\n",
    "\n",
    "                        \"precision_weighted_mean\": pW_mean,\n",
    "                        \"precision_weighted_std\":  pW_std,\n",
    "                        \"recall_weighted_mean\":    rW_mean,\n",
    "                        \"recall_weighted_std\":     rW_std,\n",
    "                        \"f1_weighted_mean\":        fW_mean,\n",
    "                        \"f1_weighted_std\":         fW_std,\n",
    "\n",
    "                        # Aggregated confusion matrix across folds\n",
    "                        \"confusion_matrix_json\": cm_to_json(cm_aggregate, labels=labels_union.tolist()),\n",
    "                    })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aee2d5",
   "metadata": {},
   "source": [
    "## Main (tests)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a157da00",
   "metadata": {},
   "source": [
    "# refference\n",
    "\n",
    "```\n",
    "VOTES = [\"modified_plurality\", \"borda\"]\n",
    "RETENTIONS = [\"always_retain\", \"never_retain\", \"different_class_retention\", \"DD_retention\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30779333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metric=euclidean | k=3 | vote=modified_plurality | retention=never_retain | fold=0\n",
      "Total time for all instances: 533.38s\n",
      "Total time for all instances: 531.93s\n",
      "metric=euclidean | k=5 | vote=modified_plurality | retention=never_retain | fold=0\n",
      "Total time for all instances: 545.78s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df_1 = \u001b[43mrun_suite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43madult\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMETRICS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding_for_metrics\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43meuclidean\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEncodingStrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mONE_HOT_ENCODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m    \u001b[49m\u001b[43mEncodingStrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mONE_HOT_ENCODE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mheom\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEncodingStrategy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLABEL_ENCODE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtest2.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrun_retentions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnever_retain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvotes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodified_plurality\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 124\u001b[39m, in \u001b[36mrun_suite\u001b[39m\u001b[34m(dataset_name, metrics, encoding_for_metrics, csv_path, run_retentions, votes)\u001b[39m\n\u001b[32m    122\u001b[39m ibl = IBL()\n\u001b[32m    123\u001b[39m ibl.fit(train_matrix)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m preds = \u001b[43mibl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtest_matrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvote\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    129\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretention_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    130\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypes\u001b[49m\n\u001b[32m    131\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    133\u001b[39m y_true = np.asarray(y_test)\n\u001b[32m    134\u001b[39m y_pred = np.asarray(preds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\src\\IBL.py:52\u001b[39m, in \u001b[36mIBL.run\u001b[39m\u001b[34m(self, test_matrix, k, metric, vote, retention_policy, types)\u001b[39m\n\u001b[32m     50\u001b[39m dist_start = time.time()\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metric == \u001b[33m\"\u001b[39m\u001b[33meuclidean\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     distances = \u001b[43meuclidean_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mX_np\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_instance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.metric == \u001b[33m\"\u001b[39m\u001b[33mcosine\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     54\u001b[39m     distances = cosine_distance(\u001b[38;5;28mself\u001b[39m.X_np, x_instance)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Daniel\\Documents\\Masters\\S1\\IML\\ML_Techniques\\src\\distance_measures.py:14\u001b[39m, in \u001b[36meuclidean_distance\u001b[39m\u001b[34m(X, x)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# X_np = X.values.astype(float)\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# instance_np = instance.values.astype(float)\u001b[39;00m\n\u001b[32m      9\u001b[39m \n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# dists = np.sqrt(np.sum((X_np - instance_np) ** 2, axis=1))\u001b[39;00m\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# return pd.DataFrame({\"Index\": np.arange(X.shape[0]), \"Distance\": dists})\u001b[39;00m\n\u001b[32m     13\u001b[39m X = np.asarray(X, dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m x = np.asarray(x, dtype=\u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m     16\u001b[39m diff = X - x\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.sqrt(np.einsum(\u001b[33m'\u001b[39m\u001b[33mij,ij->i\u001b[39m\u001b[33m'\u001b[39m, diff, diff))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "df_1 = run_suite(\n",
    "    dataset_name=\"adult\",\n",
    "    metrics=METRICS,\n",
    "    encoding_for_metrics={\n",
    "        \"euclidean\": EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"cosine\":    EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"heom\": EncodingStrategy.LABEL_ENCODE, \n",
    "    },\n",
    "    csv_path=\"test2.csv\",\n",
    "    run_retentions=[\"never_retain\"], \n",
    "    votes=[\"modified_plurality\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6e2dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = run_suite(\n",
    "    dataset_name=\"adult\",\n",
    "    metrics=METRICS,\n",
    "    encoding_for_metrics={\n",
    "        \"euclidean\": EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"cosine\":    EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"heom\": EncodingStrategy.LABEL_ENCODE, \n",
    "    },\n",
    "    csv_path=\"test.csv\",\n",
    "    run_retentions=[\"modified_plurality\"], \n",
    "    votes=[\"never_retain\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b31a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = run_suite(\n",
    "    dataset_name=\"adult\",\n",
    "    metrics=METRICS,\n",
    "    encoding_for_metrics={\n",
    "        \"euclidean\": EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"cosine\":    EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"heom\": EncodingStrategy.LABEL_ENCODE, \n",
    "    },\n",
    "    csv_path=\"test.csv\",\n",
    "    run_retentions=[\"modified_plurality\"], \n",
    "    votes=[\"different_class_retention\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86cb2d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = run_suite(\n",
    "    dataset_name=\"adult\",\n",
    "    metrics=METRICS,\n",
    "    encoding_for_metrics={\n",
    "        \"euclidean\": EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"cosine\":    EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"heom\": EncodingStrategy.LABEL_ENCODE, \n",
    "    },\n",
    "    csv_path=\"test.csv\",\n",
    "    run_retentions=[\"modified_plurality\"], \n",
    "    votes=[\"always_retain\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf4114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = run_suite(\n",
    "    dataset_name=\"adult\",\n",
    "    metrics=METRICS,\n",
    "    encoding_for_metrics={\n",
    "        \"euclidean\": EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"cosine\":    EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"heom\": EncodingStrategy.LABEL_ENCODE, \n",
    "    },\n",
    "    csv_path=\"test.csv\",\n",
    "    run_retentions=[\"modified_plurality\"], \n",
    "    votes=[\"always_retain\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde93625",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = run_suite(\n",
    "    dataset_name=\"adult\",\n",
    "    metrics=METRICS,\n",
    "    encoding_for_metrics={\n",
    "        \"euclidean\": EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"cosine\":    EncodingStrategy.ONE_HOT_ENCODE,\n",
    "        \"heom\": EncodingStrategy.LABEL_ENCODE, \n",
    "    },\n",
    "    csv_path=\"test.csv\",\n",
    "    run_retentions=[\"modified_plurality\"], \n",
    "    votes=[\"always_retain\"]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
